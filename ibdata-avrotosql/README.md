# ibdata-avrotosql

This module takes an Avro datastream and loads it into an SQL Database

This process is not likely to be fast or perfect initially.  The primary local implementation
at the moment is SQLLite, with the remote implementations being whatever IBDatabaseDialect
can be produced from a supplied JDBC URL.


 Avro Type | Liquibase Type
 -------- | -------------
 `record` |  [See below](#Records)
 `int`    | `int`
 `long`   | `bigint`
 `enum`   | `varchar(255)`
 `string` | `varchar(255)`
 `double` | `double`
 `float`  | `float`
 `decimal`| `decimal`
 `date`   | `date`
 `bytes`  | `blob`
 `fixed`  | `blob`
 `time-millis` | `time`
 `timestamp-millis` | `timestamp`
 `uuid` |  `uuid`

IBData does not currently deal with `time-micros` or `timestamp-micros`

IBData does not currently create databases or catalogs.

## Records

Records are handled specially.  There are two ways to handle records within an Avro
record as it applies to a target database table.

### Inject
Each field in a sub-record can become a field in the new row by just prepending the
Avro fieldname to it.  So a schema like

```
{
  "type" : "record",
  "name" : "test",
  "namespace" : "com.test",
  "fields" : [ {
    "name" : "index",
    "type" : {
      "type" : "int",
      "order" : "ignore"
    }
  }, {
    "name" : "e1",
    "type" : "record",
    "fields" : [ {
      "name" : "last_name",
      "type" : "string"
       }, {
      "name" : "gender",
      "type" : "string"
      }, {
      "name" : "country",
      "type" : "string"
       }, {
      "name" : "age",
      "type" : "int"
      } ], {
      "name" : "date_of_birth",
      "type" : {
        "type" : "int",
        "logicalType" : "date"
      } ]
  }, {
    "name" : "id",
    "type" : "string"
  } ]
}

```

would logically translate to fields like

```
table com_test_test

int     index
string  e1_last_name
string  e1_gender
string  e1_country
int     e1_age
date    e1_date_of_birth
string  id

```

### Lookup Table

Lookup tables are a bit more work.  In the case of the record `e1` above, there would
be a an additional table `e1` produced.  The two tables would look logically translate
to something like this

```
table com_test_test

int         index
uuid        e1
string      id

table com_test_e1
uuid        com_test_test_id
string      last_name
string      gender
string      country
int         age
date        date_of_birth

unique index (com_test_test_id)
unique index (last_name, gender, country, age, date_of_birth)

foreign key for lookup (com_test_test_e1 to com_test_e1.com_test_test_id)

```

During load, the value of `com_test_test_id` in the second (lookup )table would be generated
as a uuid based on the checksums of the other field values.

The field `com_test_test.e1` would be set to the value injected into the lookup table.
Note: As noted, there will be a unique constraint generated on every (record) field of the lookup
table.  Since that UUID is generated by data checksum, the values are  astronomically likely
to be unique and are totally deterministic.  During load, the loader will assign the
calculated id to the FK link field and the (identical) calculated value to the lookup
table.


IBData currently only does Lookup Table.  It was harder to implement, but Inject should
be easy to do after that.